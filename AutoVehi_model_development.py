# -*- coding: utf-8 -*-
"""Model Development.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zSp80RVzxoPXH49Zj8CHgMS6qV3TAJEd
"""

# Loading in our data and importing necessary packages
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from datetime import datetime


# Our data is stored on https://www.nhtsa.gov/
# We can use a command like this to upload it into Google Colab's file system
!wget -q --show-progress "https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADS.csv"

# Let's load in our dataset as a pandas dataframe
Incident_Reports_ADS = pd.read_csv("SGO-2021-01_Incident_Reports_ADS.csv")

def determine_weather(row):
    if row['Weather - Clear'] == 'Y':
        return 'Clear'
    elif row['Weather - Rain'] == 'Y':
        return 'Rain'
    elif row['Weather - Snow'] == 'Y':
        return 'Snow'
    elif row['Weather - Cloudy'] == 'Y':
        return 'Cloudy'
    elif row['Weather - Fog/Smoke'] == 'Y':
        return 'Fog/Smoke'
    elif row['Weather - Severe Wind'] == 'Y':
        return 'Severe Wind'
    elif row['Weather - Unknown'] == 'Y':
        return 'Unknown'
    elif row['Weather - Other'] == 'Y':
        return 'Other'
    else:
        return 'Unknown'

Incident_Reports_ADS['Weather'] = Incident_Reports_ADS.apply(determine_weather, axis=1)

le = LabelEncoder()
Incident_Reports_ADS['Weather'] = le.fit_transform(Incident_Reports_ADS['Weather'])
print(Incident_Reports_ADS['Weather'].unique())

# Feature selection
features = ['Weather', 'Lighting', 'Roadway Type', 'Roadway Surface', 'Incident Date', 'Incident Time (24:00)', 'Posted Speed Limit (MPH)', 'Crash With', 'Highest Injury Severity Alleged', 'CP Pre-Crash Movement', 'SV Pre-Crash Movement', 'Latitude', 'Longitude', 'City', 'State']
df = Incident_Reports_ADS[features]

# Remove rows with remaining null values
df.dropna(subset=features, inplace=True)

# Example feature engineering
# Extract hour from 'Incident Time'
# df['Incident Hour'] = pd.to_datetime(df['Incident Time (24:00)'], format='%H:%M').dt.hour

print(df['Highest Injury Severity Alleged'].unique())

num_uknown = df[df['Highest Injury Severity Alleged'] == 'Unknown'].shape[0]
print(f"Number of uknown values: {num_uknown}")

num_mod = df[df['Highest Injury Severity Alleged'] == 'Moderate'].shape[0]
print(f"Number of moderate values: {num_mod}")

num_noinjuries = df[df['Highest Injury Severity Alleged'] == 'No Injuries Reported'].shape[0]
print(f"Number of no injuries values: {num_noinjuries}")

num_minor = df[df['Highest Injury Severity Alleged'] == 'Minor'].shape[0]
print(f"Number of minor values: {num_minor}")

num_serious = df[df['Highest Injury Severity Alleged'] == 'Serious'].shape[0]
print(f"Number of serious values: {num_serious}")

num_fatality = df[df['Highest Injury Severity Alleged'] == 'Fatality'].shape[0]
print(f"Number of fatality values: {num_fatality}")

print(f"Number of values: {df['Highest Injury Severity Alleged'].shape}")

# Label Encoding for categorical features
label_encoders = {}

categorical_cols = df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

print(df.columns)

# Display cleaned data
print(df['Highest Injury Severity Alleged'].unique())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression

RANDOM_STATE = 42
TEST_SIZE = 0.2
N_ESTIMATORS = 100
N_NEIGHBORS = 5

# # Input features and output feature
# print(df.columns)

y = df[['Highest Injury Severity Alleged']]
X = df.drop(['Highest Injury Severity Alleged'], axis = 1)
# Predict? Property Damage

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)

# Define a function to evaluate models
def evaluate_model(model, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Print evaluation metrics
    print(f"=== {model_name} Model ===")
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\n" + "="*40 + "\n")

    return y_pred

# Initialize and evaluate the Random Forest model
rf_model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)
evaluate_model(rf_model, "Random Forest")

# Initialize and evaluate the K-Nearest Neighbors model
knn_model = KNeighborsClassifier(n_neighbors=N_NEIGHBORS)  # You can adjust the number of neighbors
evaluate_model(knn_model, "K-Nearest Neighbors")

# Initialize and evaluate the Decision Tree model
dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE)
evaluate_model(dt_model, "Decision Tree")

# Initialize and evaluate the Multilayer Perceptron
mlp_model = MLPClassifier(random_state=RANDOM_STATE, max_iter=1000)
evaluate_model(mlp_model, "MLP Classifier")

# Initialize and evaluate the Logistic Regression model
log_reg_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)
evaluate_model(log_reg_model, "Logistic Regression")

# ['No Injuries Reported' 'Minor' 'Unknown' 'Moderate' 'Serious' 'Fatality']
# [3 1 5 2 4 0]
# Number of uknown values: 60
# Number of moderate values: 33
# Number of no injuries values: 935
# Number of minor values: 117
# Number of serious values: 21
# Number of fatality values: 2

n_estimators_list = [50, 100, 200]
max_depth_list = [1, 10, 20, 30, 40, 100, 200]
results = []
AVG_ROUND = 1

for n_estimators in n_estimators_list:
    for max_depth in max_depth_list:
        avg_accuracy = 0
        for i in range(AVG_ROUND):
          rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
          rf_model.fit(X_train, y_train)
          y_pred = rf_model.predict(X_test)
          accuracy = accuracy_score(y_test, y_pred)
          avg_accuracy += accuracy

        avg_accuracy /= AVG_ROUND
        # print(f"n_estimators: {n_estimators}, max_depth: {max_depths}, accuracy: {avg_accuracy}")

        result = {
                  'n_estimators': n_estimators,
                  'max_depth': max_depth,
                  'accuracy': accuracy
              }
        results.append(result)
        # evaluate_model(rf_model, f"Random Forest (n_estimators={n_estimators}, random_state={random_state})")
for result in results:
    print(f"n_estimators: {result['n_estimators']}, max_depth: {result['max_depth']}, accuracy: {result['accuracy']:.3f}")

# Our data is stored on https://www.nhtsa.gov/
# We can use a command like this to upload it into Google Colab's file system
!wget -q --show-progress "https://static.nhtsa.gov/odi/ffdd/sgo-2021-01/SGO-2021-01_Incident_Reports_ADAS.csv"

# Let's load in our dataset as a pandas dataframe
Incident_Reports_ADAS = pd.read_csv("SGO-2021-01_Incident_Reports_ADAS.csv")

Incident_Reports_ADAS['Weather'] = Incident_Reports_ADAS.apply(determine_weather, axis=1)
Incident_Reports_ADAS['Weather'] = le.fit_transform(Incident_Reports_ADAS['Weather'])

# Feature selection for ADAS
features = ['Weather', 'Lighting', 'Roadway Type', 'Roadway Surface', 'Incident Date', 'Incident Time (24:00)',
            'Posted Speed Limit (MPH)', 'Crash With', 'Highest Injury Severity Alleged', 'CP Pre-Crash Movement',
            'SV Pre-Crash Movement', 'Latitude', 'Longitude', 'City', 'State']
adas_df = Incident_Reports_ADAS[features]

# Remove rows with remaining null values in ADAS
adas_df.dropna(subset=features, inplace=True)

# Label Encoding for ADAS dataset
for col in categorical_cols:
    adas_df[col] = le.fit_transform(adas_df[col])

# Split the data into training and testing sets for ADAS
y_adas = adas_df[['Highest Injury Severity Alleged']]
X_adas = adas_df.drop(['Highest Injury Severity Alleged'], axis=1)
X_train_adas, X_test_adas, y_train_adas, y_test_adas = train_test_split(X_adas, y_adas, test_size=TEST_SIZE, random_state=RANDOM_STATE)

def evaluate_adas_model(model, model_name):
    model.fit(X_train_adas, y_train_adas)
    y_pred_adas = model.predict(X_test_adas)

    print(f"=== {model_name} Model (ADAS) ===")
    print(f"Accuracy: {accuracy_score(y_test_adas, y_pred_adas)}")
    print("Classification Report:")
    print(classification_report(y_test_adas, y_pred_adas))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test_adas, y_pred_adas))
    print("\n" + "="*40 + "\n")

    return y_pred_adas

# Evaluate the ADAS models
evaluate_adas_model(RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE), "Random Forest")
evaluate_adas_model(KNeighborsClassifier(n_neighbors=N_NEIGHBORS), "K-Nearest Neighbors")
evaluate_adas_model(DecisionTreeClassifier(random_state=RANDOM_STATE), "Decision Tree")
evaluate_adas_model(MLPClassifier(random_state=RANDOM_STATE, max_iter=1000), "MLP Classifier")
evaluate_adas_model(LogisticRegression(max_iter=1000, random_state=RANDOM_STATE), "Logistic Regression")

# Visualization and Comparison between ADS and ADAS
ads_accuracies = [0.92, 0.79, 0.87, 0.79, 0.78]  # Replace with your actual accuracies
adas_accuracies = [0.96, 0.85, 0.89, 0.87, 0.89]  # Replace with your actual accuracies

models = ['Random Forest', 'KNN', 'Decision Tree', 'MLP', 'Logistic Regression']

plt.figure(figsize=(10, 6))
bar_width = 0.35
index = np.arange(len(models))

bar1 = plt.bar(index, ads_accuracies, bar_width, label='ADS')
bar2 = plt.bar(index + bar_width, adas_accuracies, bar_width, label='ADAS')

plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Model Comparison between ADS and ADAS Datasets')
plt.xticks(index + bar_width / 2, models)
plt.legend()

plt.tight_layout()
plt.show()

# Example quantitative comparison (accuracy difference)
accuracy_diff = np.array(ads_accuracies) - np.array(adas_accuracies)
print(f"Accuracy differences between ADS and ADAS: {accuracy_diff}")

"""## **Relevant Hyperparameters:**

1. **Random Forest**
*   n_estimators: Number of trees in the forest. A higher number usually improves performance but increases computation time.
*   max_depth: Maximum depth of the tree. Controls the complexity of the model. A smaller value might reduce overfitting.

2. **K-Nearest Neighbors (KNN)**

*   n_neighbors: Number of neighbors to use. Controls the balance between bias and variance.
*   weights: Weight function used in prediction. Options include uniform (all points in each neighborhood are weighted equally) and distance (closer neighbors have greater influence).

3. **Decision Tree**
* max_depth: Maximum depth of the tree. Limits the growth of the tree to avoid
overfitting.
* min_samples_split: The minimum number of samples required to split an internal node. Higher values prevent the model from learning overly specific patterns (overfitting).

4. **Multilayer Perceptron (MLP)**
* hidden_layer_sizes: The number of neurons in the hidden layers. The architecture of the neural network significantly affects its learning capacity.
* alpha: Regularization parameter. Prevents overfitting by penalizing large weights.

5. **Logistic Regression**
* C: Inverse of regularization strength. Smaller values specify stronger regularization.
* solver: Algorithm to use in the optimization problem. The choice can affect convergence and speed.

"""

from sklearn.model_selection import GridSearchCV

# Define a function to evaluate models and print the best hyperparameters
def evaluate_model_with_tuning(grid_search, model_name):
    # Fit the model using GridSearchCV
    grid_search.fit(X_train, y_train)

    # Print the best hyperparameters found by GridSearchCV
    print(f"=== {model_name} (Tuned) ===")
    print(f"Best Hyperparameters: {grid_search.best_params_}")

    # Predict on the test set using the best estimator
    y_pred = grid_search.best_estimator_.predict(X_test)

    # Print evaluation metrics
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\n" + "="*40 + "\n")

# 1. Random Forest
param_grid_rf = {
    'n_estimators': [50, 100, 200],3
    'max_depth': [None, 10, 20, 30, 100, 200]
}
rf_grid = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE), param_grid_rf, cv=5, n_jobs=-1, verbose=2)
evaluate_model_with_tuning(rf_grid, "Random Forest")

# 2. K-Nearest Neighbors
param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance']
}
knn_grid = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, n_jobs=-1, verbose=2)
evaluate_model_with_tuning(knn_grid, "K-Nearest Neighbors")

# 3. Decision Tree
param_grid_dt = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}
dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_STATE), param_grid_dt, cv=5, n_jobs=-1, verbose=2)
evaluate_model_with_tuning(dt_grid, "Decision Tree")

# 4. Multilayer Perceptron
param_grid_mlp = {
    'hidden_layer_sizes': [(50,), (100,), (100, 50)],
    'alpha': [0.0001, 0.001, 0.01]
}
mlp_grid = GridSearchCV(MLPClassifier(random_state=RANDOM_STATE, max_iter=1000), param_grid_mlp, cv=5, n_jobs=-1, verbose=2)
evaluate_model_with_tuning(mlp_grid, "MLP Classifier")

# 5. Logistic Regression
param_grid_log_reg = {
    'C': [0.01, 0.1, 1, 10],
    'solver': ['newton-cg', 'lbfgs', 'liblinear']
}
log_reg_grid = GridSearchCV(LogisticRegression(random_state=RANDOM_STATE, max_iter=1000), param_grid_log_reg, cv=5, n_jobs=-1, verbose=2)
evaluate_model_with_tuning(log_reg_grid, "Logistic Regression")

'''
Key Components of GridSearchCV:
estimator: The machine learning model you want to tune (e.g., RandomForestClassifier, LogisticRegression).

param_grid: A dictionary or list of dictionaries with hyperparameters and their corresponding ranges/values to be tested.

cv: The number of cross-validation folds to use (default is 5). This is where the data is split into cv number of folds to validate the model.

scoring: The performance metric used to evaluate the model (e.g., accuracy, precision, recall). If not specified, GridSearchCV uses the estimator's default scoring method.

n_jobs: The number of CPU cores to use for parallel processing. -1 uses all available cores.

verbose: Controls the level of output verbosity.
'''

"""Meshgrid Creation:

np.meshgrid is used to create a grid of n_estimators and max_depth values. This grid allows you to evaluate every combination of the two hyperparameters.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from mpl_toolkits.mplot3d import Axes3D

# Define the range of hyperparameters
n_estimators_range = np.arange(1, 601, 10)
max_depth_range = np.arange(1, 51, 2)

# Create a meshgrid for the hyperparameters
n_estimators_grid, max_depth_grid = np.meshgrid(n_estimators_range, max_depth_range)

# Initialize an array to store accuracy results
accuracy_grid = np.zeros(n_estimators_grid.shape)

# Loop over all combinations of n_estimators and max_depth
for i in range(n_estimators_grid.shape[0]):
    for j in range(n_estimators_grid.shape[1]):
        # Set hyperparameters
        n_estimators = n_estimators_grid[i, j]
        max_depth = max_depth_grid[i, j]

        # Train the model with current hyperparameters
        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=RANDOM_STATE)
        model.fit(X_train, y_train)

        # Predict and calculate accuracy
        y_pred = model.predict(X_test)
        accuracy_grid[i, j] = accuracy_score(y_test, y_pred)

# Create a 3D surface plot
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(n_estimators_grid, max_depth_grid, accuracy_grid, cmap='viridis')

# Add labels and title
ax.set_xlabel('n_estimators')
ax.set_ylabel('max_depth')
ax.set_zlabel('Accuracy')
ax.set_title('Random Forest: Accuracy vs n_estimators and max_depth')

plt.show()